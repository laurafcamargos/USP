<?xml version="1.0" encoding="utf-8" ?><transcript><text start="0.76" dur="5.28">there&amp;#39;s a lot of chatter about AI right</text><text start="3.24" dur="5.56">now we&amp;#39;re not used to consuming language</text><text start="6.04" dur="5.599">that wasn&amp;#39;t produced by humans suddenly</text><text start="8.8" dur="4.08">you&amp;#39;re talking to something that feels</text><text start="11.639" dur="2.08">very much like there&amp;#39;s a human on the</text><text start="12.88" dur="3.84">other</text><text start="13.719" dur="5.241">side these large language models can</text><text start="16.72" dur="2.24">give you</text><text start="20.199" dur="3.281">Goosebumps this question of whether</text><text start="22" dur="4.039">language models can</text><text start="23.48" dur="4.44">actually have meaning learn meaning</text><text start="26.039" dur="3.4">encode meaning is probably one of the</text><text start="27.92" dur="3.439">most fundamental or most debated</text><text start="29.439" dur="4.481">questions right now now there&amp;#39;s this</text><text start="31.359" dur="3.841">crazy opportunity to learn a ton about</text><text start="33.92" dur="4.52">Ai and about</text><text start="35.2" dur="5.8">humans what does it mean to be</text><text start="38.44" dur="5.52">intelligent what does it mean to think</text><text start="41" dur="5.96">and to reason how do you know that a</text><text start="43.96" dur="3">system is behaving</text><text start="47.76" dur="3.799">intelligently we&amp;#39;ve been taking these</text><text start="49.6" dur="3.599">generative AI systems and trying to</text><text start="51.559" dur="5">understand really how they work under</text><text start="53.199" dur="5.52">the hood they slurp up an enormous</text><text start="56.559" dur="3.48">amount of data like the entire internet</text><text start="58.719" dur="3.961">but all they&amp;#39;re actually doing at a very</text><text start="60.039" dur="4.921">basic level is literally to just predict</text><text start="62.68" dur="4.68">the next word in a</text><text start="64.96" dur="4.32">sentence so they&amp;#39;re just learning a very</text><text start="67.36" dur="3.6">good probability distribution over what</text><text start="69.28" dur="4.76">those next words look</text><text start="70.96" dur="4.519">like what is going on when you ask a</text><text start="74.04" dur="3.8">language model question and it gives you</text><text start="75.479" dur="4.081">an answer there&amp;#39;s some process that</text><text start="77.84" dur="3.4">connected that input to the output we&amp;#39;re</text><text start="79.56" dur="3.8">trying to figure out what that process</text><text start="81.24" dur="3.36">is and then we&amp;#39;ve been doing a lot of</text><text start="83.36" dur="3.36">work with cognitive science with</text><text start="84.6" dur="3.839">Neuroscience to try to ask similar</text><text start="86.72" dur="4.6">questions about humans and then just say</text><text start="88.439" dur="5.72">how similar are these two</text><text start="91.32" dur="4.96">processes the relationship between Ai</text><text start="94.159" dur="4.201">and Neuroscience it&amp;#39;s always been there</text><text start="96.28" dur="3.64">because both of them are about</text><text start="98.36" dur="3.88">intelligence and the nature of</text><text start="99.92" dur="4.92">intelligence the kind of similarity has</text><text start="102.24" dur="4.199">become even stronger in recent years</text><text start="104.84" dur="2.879">because the nature of the artificial</text><text start="106.439" dur="3.28">intelligence models we have right now</text><text start="107.719" dur="4.44">are things that to a large extent we</text><text start="109.719" dur="5.36">stumbled upon they are not carefully</text><text start="112.159" dur="7">engineered systems the way AI systems of</text><text start="115.079" dur="6.68">the 1980s and 90s were we&amp;#39;re just like</text><text start="119.159" dur="4.88">oops it now speaking language as well as</text><text start="121.759" dur="3.921">humans and so now we&amp;#39;re very much in the</text><text start="124.039" dur="4.521">position that neuroscientists are which</text><text start="125.68" dur="5.44">is I have this system it&amp;#39;s a complicated</text><text start="128.56" dur="4.36">system it has a behavior and I need to</text><text start="131.12" dur="4.56">come up with a theory that explains the</text><text start="132.92" dur="2.76">behavior and predicts the</text><text start="136.879" dur="4.321">behavior there&amp;#39;s this kind of feeling</text><text start="139.36" dur="4.56">that because they&amp;#39;ve only had access to</text><text start="141.2" dur="4.319">text and not to the actual World large</text><text start="143.92" dur="3.599">language models can&amp;#39;t really encode</text><text start="145.519" dur="4.881">meaning because meaning is about what&amp;#39;s</text><text start="147.519" dur="4.761">in the actual world the is large</text><text start="150.4" dur="4.36">language models their neural networks</text><text start="152.28" dur="4.44">and they have billions and billions of</text><text start="154.76" dur="3.68">individual numbers that are playing some</text><text start="156.72" dur="4.439">role and so we have to figure out how to</text><text start="158.44" dur="5.32">sift through those and pull out pieces</text><text start="161.159" dur="4.481">of them so when I use a word like apple</text><text start="163.76" dur="4.8">there&amp;#39;s this huge web of stuff I know</text><text start="165.64" dur="4.72">about apples a crisp fall afternoon and</text><text start="168.56" dur="5.319">walking out in the orchard going apple</text><text start="170.36" dur="5.76">picking with my kids making pies there&amp;#39;s</text><text start="173.879" dur="3.961">obviously a huge part of the meaning of</text><text start="176.12" dur="4.08">a word that comes from sensory</text><text start="177.84" dur="4.72">experience um but then there&amp;#39;s a huge</text><text start="180.2" dur="4.08">part that doesn&amp;#39;t how much could a</text><text start="182.56" dur="3.64">language model that has really good</text><text start="184.28" dur="3.679">access to a lot of data generated by</text><text start="186.2" dur="4.52">humans who did have access to the real</text><text start="187.959" dur="5.721">world can it proxy or even get the real</text><text start="190.72" dur="2.96">thing just from that</text><text start="194.599" dur="5.401">text how to actually look for these</text><text start="198" dur="4.159">Concepts or this meaning within large</text><text start="200" dur="3.44">language models these are really really</text><text start="202.159" dur="2.64">big questions we don&amp;#39;t have the ansers</text><text start="203.44" dur="2.6">to them and we should be open-minded in</text><text start="204.799" dur="3.921">trying to study</text><text start="206.04" dur="5.119">them I don&amp;#39;t think these systems are</text><text start="208.72" dur="3.92">human level um but I think there&amp;#39;s</text><text start="211.159" dur="3.121">things that are happening inside them</text><text start="212.64" dur="3.879">that are</text><text start="214.28" dur="4.28">non-trivial within my lab within a</text><text start="216.519" dur="4.561">single project we will have results that</text><text start="218.56" dur="5.039">simultaneously suggest that the model is</text><text start="221.08" dur="4.2">actually quite clever and represents</text><text start="223.599" dur="3.28">things in a way that we would call</text><text start="225.28" dur="3.56">systematic and compositional and</text><text start="226.879" dur="5.041">humanlike in this certain way and at the</text><text start="228.84" dur="5.239">same time is just doing something wild</text><text start="231.92" dur="5.319">that just seems simply dumb right you&amp;#39;re</text><text start="234.079" dur="5.401">just like this model is so dumb and and</text><text start="237.239" dur="3.521">those things can kind of both be true I</text><text start="239.48" dur="2.44">think that&amp;#39;s the kind of world we&amp;#39;re in</text><text start="240.76" dur="4.72">right now that makes the science so</text><text start="241.92" dur="3.56">messy and so interesting</text><text start="248.49" dur="12.349">[Music]</text></transcript>